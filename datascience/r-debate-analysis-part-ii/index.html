<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>More republican debate analysis with R | En El Margen</title>
  <meta name="viewport" content="width=device-width">


  <!-- syntax highlighting CSS -->
  <link rel="stylesheet" href="/css/syntax.css">

  <!-- CSS -->
  <link rel="stylesheet" href="/css/reset.css">
  <link rel="stylesheet" href="/css/main.css">
  <!-- <link href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet"> -->


  <!-- Fonts -->
  <link href='http://fonts.googleapis.com/css?family=Bitter:400,700,400italic|Open+Sans:400italic,600italic,400,600' rel='stylesheet' type='text/css'>
  
  
  <link rel="stylesheet" href="/css/post.css">
  

</head>
<body>
  <header style="background-image: url(/images/cover.jpg);">
  <div class="container post-container">
    <a href="/" class="home_button"></a>
    <div class="inner-container">
      <ul class="meta">
        <li>
        <p style="color:white">Publicado: 07 Jan 2016</p>
        </li>
        <li>
            <p style="color:white">Archivado en: r-english, datascience</p>
        </li>
      </ul>      
    </div>
    <ul class="pagination">
      
        <li class="previous">
          <a href="/economia/Conocer-Mexico/">
            Previous
          </a>
        </li>
      
      
      <li class="next">
        <a href="/datascience/r-debate-analysis-part-iii/">
          Next
        </a>
      </li>
      
    </ul>
  </div>
</header>
<article>
    <div id="topbar">
      
    </div>
  <div class="container">
    <h1>More republican debate analysis with R</h1>
    <p>A few weeks late, here is a follow-up analysis using <em>R</em>, of the transcript of the latest Republican primary debate held at Las Vegas, Nevada.</p>

<p>Like the previous post, it should be interesting to see some word-clouds and some trends from the front-runners (and <em>of course</em>, Donald Trump).</p>

<h2 id="getting-and-cleaning-the-data">Getting and cleaning the data</h2>

<p>As in the last post, we’re going to import the data and clean with a function that was <a href="http://enelmargen.org/datascience/republican-debates/index.html">nicely improved by Alan Jordan</a>:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># some packages for scraping and cleaning the data
library(rvest)
library(plyr)
library(dplyr)
library(stringi)
library(magrittr)

# function to partially separate and clean into a data.frame a debate from the presidency project
MakeDebateDF&lt;-function(df){
  newdf &lt;- data.frame(
    person = apply(df, 
                   MARGIN = 1, 
                   function(x){
                     stri_extract_first_regex(x, 
                                              &quot;[A-Z&#39;-]+(?=(:\\s))&quot;)
                   }),
    message = apply(df, 
                    MARGIN = 1, 
                    function(x){
                      stri_replace_first_regex(x,
                                               &quot;[A-Z&#39;-]+:\\s+&quot;, 
                                               &quot;&quot;)
                    }),
    stringsAsFactors=FALSE
  )
  for (j in 2:nrow(newdf)) { 
  if (is.na(newdf[j,&#39;person&#39;])) 
		{newdf[j,&#39;person&#39;] &lt;-  newdf[(j-1),&#39;person&#39;] }
	}

  return(newdf)
}</code></pre></figure>

<p>This time i’m only downloading one debate, and joining with the last four I had parsed…</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># Importing debates --- 
# url for all debates
url &lt;- &quot;http://www.presidency.ucsb.edu/ws/index.php?pid=&quot;

### -------- debate in Las Vegas, Nevada (fifth debate)
lasvegas &lt;- &quot;111177&quot;

debate_v &lt;- read_html(paste0(url, lasvegas)) %&gt;% 
  html_nodes(&quot;p&quot;) %&gt;%
  html_text()

debate_v &lt;- ldply(debate_v, rbind)
debate_v &lt;- MakeDebateDF(debate_v)</code></pre></figure>

<h2 id="analyzing">Analyzing</h2>
<p>Let’s join this data with the previous debates and see some stats and wordclouds…</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># the last 4 debates were stored in &quot;all_debates&quot; object...
all_debates &lt;- rbind(all_debates, 
                     debate_v)</code></pre></figure>

<p>Because he’s the most interesting to watch, let’s see what Trump says overall and in this debate…</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r">library(ggplot2)
# this is for order_axis and theme_eem
# it can be downloaded using 
# devtools::install_github(&quot;eflores89/eem&quot;)
library(eem)
# all debates
trump_words &lt;- apply(subset(all_debates, person == &quot;TRUMP&quot;)[&#39;message&#39;],
                    1,
                    paste)
# cloud
# function taken from: 
# http://www.sthda.com/english/wiki/word-cloud-generator-in-r-one-killer-function-to-do-everything-you-need
trump_cloud &lt;- rquery.wordcloud(trump_words, 
    &quot;text&quot;, 
    max.words = 300,
    excludeWords = c(&quot;going&quot;,&quot;and&quot;,
                    &quot;applause&quot;,&quot;get&quot;,
                    &quot;got&quot;,&quot;let&quot;))

trump_freq &lt;- trump_cloud$freqTable

# debate in Las Vegas
trump_words_l &lt;- apply(subset(debate_v, person == &quot;TRUMP&quot;)[&#39;message&#39;],
                    1,
                    paste)
trump_cloud_l &lt;- rquery.wordcloud(trump_words_l, 
    &quot;text&quot;, 
    max.words = 300,
    excludeWords = c(&quot;going&quot;,&quot;and&quot;,
                    &quot;applause&quot;,&quot;get&quot;,
                    &quot;got&quot;,&quot;let&quot;))

trump_freq_l &lt;- trump_cloud_l$freqTable</code></pre></figure>

<h2 id="overall-word-cloud">Overall word-cloud</h2>

<p><img src="/images/posts/trump_cloud2.png" alt="Donald Trump all debates wordcloud" /></p>

<h2 id="las-vegas">Las Vegas</h2>

<p><img src="/images/posts/trump_cloud_lv.png" alt="Donald Trump las vegas debate word cloud" /></p>

<h2 id="shifts-in-speech">Shifts in speech</h2>

<p>Of course, over the same five debates, topics have shifted tremendously both among the contenders and Trump.</p>

<p>For example, let’s see what the most spoken words were by debate…</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># using previous data for each debate....
debate_words_h &lt;- rquery.wordcloud(x = debate_h$message) #ohio, 1st
  # just the frequency table...
  # a bit lazy to do myself!
  debate_words_h &lt;- debate_words_h$freq %&gt;% mutate(&quot;Debate&quot; = &quot;Ohio&quot;)
debate_words_c &lt;- rquery.wordcloud(x = debate_c$message) #cali, 2nd
  debate_words_c &lt;- debate_words_c$freq %&gt;% mutate(&quot;Debate&quot; = &quot;California&quot;)
debate_words_b &lt;- rquery.wordcloud(x = debate_b$message) #boulder, 3rd
  debate_words_b &lt;- debate_words_b$freq %&gt;% mutate(&quot;Debate&quot; = &quot;Boulder&quot;)
debate_words_w &lt;- rquery.wordcloud(x = debate_w$message) #wisc, 4th
  debate_words_w &lt;- debate_words_w$freq %&gt;% mutate(&quot;Debate&quot; = &quot;Wisconsin&quot;)
debate_words_v &lt;- rquery.wordcloud(x = debate_v$message) #vegas, 5th
  debate_words_v &lt;- debate_words_v$freq %&gt;% mutate(&quot;Debate&quot; = &quot;LasVegas&quot;)

# join all
all_debate_words &lt;- rbind.data.frame(debate_words_h, debate_words_c) 
all_debate_words &lt;- rbind.data.frame(all_debate_words, debate_words_b) 
all_debate_words &lt;- rbind.data.frame(all_debate_words, debate_words_w) 
all_debate_words &lt;- rbind.data.frame(all_debate_words, debate_words_v) 

# graph with some interesting words...
interesting_words &lt;- subset(all_debate_words, word %in% c(&quot;government&quot;,
                                              &quot;isis&quot;,&quot;president&quot;,&quot;senator&quot;,
                                              &quot;money&quot;, &quot;jobs&quot;, &quot;tax&quot;, &quot;obama&quot;,
                                              &quot;clinton&quot;, &quot;america&quot;))

interesting_words$Debate &lt;- factor(interesting_words$Debate, 
                          levels = c(&quot;Ohio&quot;,&quot;California&quot;,
                                     &quot;Boulder&quot;,&quot;Wisconsin&quot;,
                                     &quot;LasVegas&quot;))

ggplot(data = interesting_words, 
        aes(x = Debate, 
            y = freq, 
            group = word)) + 
        geom_line(aes(colour = word)) +
        theme_eem() +
        scale_colour_eem(20) + 
        labs(x = &quot;Debate&quot;, 
             y = &quot;Frequency&quot;, 
             title = &quot;Shifts in speech&quot;)</code></pre></figure>

<p>Apparently, “tax” is out: it wasn’t even mentioned this past debate, in contrast with the increasingly present “isis”. “Clinton” and “obama” are a constant:</p>

<p><img src="/images/posts/shifts_p2.png" alt="shifts in speech republican debates" /></p>

<h2 id="aggregate-stats">Aggregate stats</h2>

<p>Now lets see some aggregate stats by contender.</p>

<blockquote>
  <p>This function is a bit confusing and/or unnecesary, I’ll probably find a better way to do this in the future…</p>
</blockquote>

<figure class="highlight"><pre><code class="language-r" data-lang="r">UnlistAndExtractInfo &lt;- function(candidate){
# this function is not general - it only applies to these particular debates...
# all the debates must be named the same in the parent env.
# for example: debate_h ...

allwords_1 &lt;- tolower(unlist(
              stri_extract_all_words(
              apply(
              subset(debate_h, person == candidate)[&#39;message&#39;],
                    1,
                    paste))))
allwords_2 &lt;- tolower(unlist(
              stri_extract_all_words(
              apply(
              subset(debate_c, person == candidate)[&#39;message&#39;],
                    1,
                    paste))))
allwords_3 &lt;- tolower(unlist(
              stri_extract_all_words(
              apply(
              subset(debate_b, person == candidate)[&#39;message&#39;],
                    1,
                    paste))))
allwords_4 &lt;- tolower(unlist(
              stri_extract_all_words(
              apply(
              subset(debate_w, person == candidate)[&#39;message&#39;],
                    1,
                    paste))))
allwords_5 &lt;- tolower(unlist(
              stri_extract_all_words(
              apply(
              subset(debate_v, person == candidate)[&#39;message&#39;],
                    1,
                    paste))))
df_insights &lt;- data.frame(
debate = c(&quot;Ohio&quot;, &quot;California&quot;, &quot;Colorado&quot;, &quot;Wisconsin&quot;,&quot;Vegas&quot;),
average_intervention = c(mean(stri_count_words(
                        apply(
                          subset(debate_h, person == candidate)[&#39;message&#39;],
                                  1,
                        paste))),
                        mean(stri_count_words(
                        apply(
                          subset(debate_c, person == candidate)[&#39;message&#39;],
                                  1,
                        paste))),
                        mean(stri_count_words(
                        apply(
                          subset(debate_b, person == candidate)[&#39;message&#39;],
                                  1,
                        paste))),
                        mean(stri_count_words(
                        apply(
                          subset(debate_w, person == candidate)[&#39;message&#39;],
                                  1,
                        paste))),
                        mean(stri_count_words(
                        apply(
                          subset(debate_c, person == candidate)[&#39;message&#39;],
                                  1,
                        paste)))
                        ),
words_total = c(length(allwords_1),
                length(allwords_2),
                length(allwords_3),
                length(allwords_4),
                length(allwords_5)),
words_unique = c(length(unique(allwords_1)),
                 length(unique(allwords_2)),
                 length(unique(allwords_3)),
                 length(unique(allwords_4)),
                 length(unique(allwords_5))
                 ),
words_repeated_fromfirst = c(0, sum(allwords_2 %in% allwords_1), 
                            sum(allwords_3 %in% allwords_1),
                            sum(allwords_4 %in% allwords_1),
                            sum(allwords_5 %in% allwords_1)),
unique_words_repeated_fromfirst = c(0,
                            length(unique(allwords_2[allwords_2 %in% allwords_1])),
                            length(unique(allwords_3[allwords_3 %in% allwords_1])),
                            length(unique(allwords_4[allwords_4 %in% allwords_1])),
                            length(unique(allwords_5[allwords_5 %in% allwords_1]))
                            ),
words_repeated_fromsecond = c(0, 0, 
                            sum(allwords_3 %in% allwords_2),
                            sum(allwords_4 %in% allwords_2),
                            sum(allwords_5 %in% allwords_2)),
unique_words_repeated_fromsecond = c(0, 0,
                            length(unique(allwords_3[allwords_3 %in% allwords_2])),
                            length(unique(allwords_4[allwords_4 %in% allwords_2])),
                            length(unique(allwords_5[allwords_5 %in% allwords_2]))
                            ),
words_repeated_fromthird = c(0, 0, 0,
                            sum(allwords_4 %in% allwords_3),
                            sum(allwords_5 %in% allwords_3)),
unique_words_repeated_fromthird = c(0, 0, 0,
                            length(unique(allwords_4[allwords_4 %in% allwords_3])),
                            length(unique(allwords_5[allwords_5 %in% allwords_3]))
                            )
, stringsAsFactors = FALSE)
return(df_insights)
}

# going to create a data frame with all the counts from the top candidates...
candidates &lt;- c(&quot;TRUMP&quot;,&quot;CARSON&quot;,&quot;RUBIO&quot;,
                &quot;KASICH&quot;,&quot;CRUZ&quot;,&quot;BUSH&quot;,
                &quot;FIORINA&quot;,&quot;PAUL&quot;,&quot;CHRISTIE&quot;)
info &lt;- NULL
info_all &lt;- NULL
for(i in 1:9){
info &lt;- UnlistAndExtractInfo(candidates[i])
info$CANDIDATE &lt;- candidates[i]
info_all &lt;- rbind(info_all, info)
}

# i&#39;m going to add a few more columns...
info_all %&lt;&gt;% mutate(carry_over_p1 = unique_words_repeated_fromfirst/words_unique,
                     word_repeat = words_total/words_unique)</code></pre></figure>

<p>Using this information to graph…</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># graph of most words spoken by debate
ggplot(order_axis(
  subset(info_all, debate != &quot;Ohio&quot; &amp; CANDIDATE != &quot;CHRISTIE&quot;), # christie didn&#39;t go to wisconsin
    CANDIDATE, carry_over_p1), 
       aes(x = CANDIDATE_o, 
           y = carry_over_p1)) + 
  geom_bar(stat = &quot;identity&quot;, 
           aes(fill = CANDIDATE_o)) + 
  facet_grid(debate ~.) + 
  theme_eem() +
  scale_fill_eem(20) + 
  labs(title = &quot;Repetition of words by candidate&quot;, 
       x = &quot;Candidate&quot;, 
       y = &quot;% of unique words repeated from first debate&quot;)</code></pre></figure>

<p>As the graph shows, Trump continues to lead in repetitiveness. In the latest debate, the Donald repeated 44.8% of the words he said during the first debate, followed by 38% from Kasich and 36% from Bush.</p>

<p>This is a key metric Trump has been consistently winning…</p>

<p><img src="/images/posts/reps_part2.png" alt="repetitions_trump" /></p>

<p>Again, if we plot total words versus unique words, to find the repetition of each individual word, we find Mr. Trump consistently below the trend: he says each word much more than the average candidate.</p>

<p>On the other hand, Carson and Fiorina tend to have a larger vocabulary of words.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r">ggplot(subset(info_all,CANDIDATE != &quot;CHRISTIE&quot;), 
       aes(x = words_total, 
           y = words_unique)) + 
    geom_point(aes(colour = CANDIDATE), size = 3, shape = 2) +
    stat_smooth()+
    theme_eem()+ # uses &quot;eflores/eem&quot;
    scale_colour_eem(20) + # uses &quot;eflores/eem&quot;
    labs(title = &quot;Words per Debate&quot;,
         x = &quot;Total Words&quot;, 
         y = &quot;Unique Words&quot;)</code></pre></figure>

<p><img src="/images/posts/words_debate_2.png" alt="unique words vs words by debate" /></p>

<p>Aggregating over the whole gives us a sense of this difference much more clearly:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># average times unique word is repeated...

ggplot(info_all, 
       aes(x = factor(CANDIDATE), 
           y = word_repeat, fill = eem_colors[1])) +
  geom_boxplot() +
  theme_eem()+
  labs(title = &quot;Average repetition of unique words&quot;,
       x = &quot;Candidate&quot;, 
       y = &quot;Repetitions&quot;) + theme(legend.position = &quot;none&quot;)</code></pre></figure>

<p><img src="/images/posts/wordsxunique_2.png" alt="words per unique word" /></p>

<h2 id="speed-of-intervention">Speed of Intervention</h2>

<p>This last debate also had the effect of spreading the gap between Trump and his opponents in terms of speed in interventions. Every time he talks, he always says less words, but this was even more apparent in Las Vegas…</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"># order the debates...
info_all$debate &lt;- factor(info_all$debate, 
                          levels = c(&quot;Ohio&quot;,&quot;California&quot;,
                                     &quot;Colorado&quot;,&quot;Wisconsin&quot;,
                                     &quot;Vegas&quot;))

# average length of interventions
ggplot(info_all, 
       aes(x = debate, 
           y = average_intervention, 
           group = CANDIDATE)) + 
  geom_path(aes(colour = CANDIDATE)) + 
  theme_eem() + 
  scale_colour_eem(20) + 
  labs(x = &quot;Debate&quot;, 
       y = &quot;Words&quot;, 
       title = &quot;Average words per intervention&quot;)</code></pre></figure>

<p><img src="/images/posts/intervention_debs.png" alt="words by intervention" /></p>

<p>This can also be an indication of how popular he is or how much “hits” he’s taking. When you need to counter an argument, sometimes only a few words is enough. If you do this constantly more than the others, the average is bound to go down.</p>

<h2 id="the-data">The Data</h2>

<p>As Alan Jordan suggested, i’ve left this data openly available via github, so anyone can play around with it and find a few more insights. <a href="https://github.com/Eflores89/proyectos/tree/master/data/us_debates">Here</a> is the link.</p>

<ul>
  <li>The <code>all_debates</code> data.frame contains two columns: candidate and message. This is all of the debates.</li>
  <li><code>debate_h</code> is the Ohio debate.</li>
  <li><code>debate_c</code> is the California debate.</li>
  <li><code>debate_b</code> is the Boulder debate.</li>
  <li><code>debate_w</code> is the Wisconsin debate.</li>
  <li><code>debate_v</code> is the Las Vegas debate.</li>
  <li>The <code>info_all</code> data.frame is the aggregate stats of contenders by debate. It contains word counts, unique word counts, etc.</li>
</ul>

  </div>
</article>

</body>
</html>
